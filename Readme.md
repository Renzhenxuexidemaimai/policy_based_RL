# Related Papers

* A3C

  [Asynchronous Methods for Deep Reinforcement Learning](http://arxiv.org/abs/1602.01783)

* ACER

  [Sample Efficient Actor-Critic with Experience Replay](http://arxiv.org/abs/1611.01224)

* TRPO

  [Trust Region Policy Optimization](http://arxiv.org/abs/1502.05477)

* PPO

  [Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347v2)

* ICM

  [Curiosity-driven Exploration by Self-supervised Prediction](http://arxiv.org/abs/1705.05363)

* RND

  [Exploration by Random Network Distillation](http://arxiv.org/abs/1810.12894)

* DDPG

  [Continuous control with deep reinforcement learning](http://arxiv.org/abs/1509.02971)

* TD3

  [Addressing Function Approximation Error in Actor-Critic Methods](http://arxiv.org/abs/1802.09477)

* SAC

  [Soft Actor-Critic Algorithms and Applications](http://arxiv.org/abs/1812.05905)

  [Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor](http://arxiv.org/abs/1801.01290)

  [Soft Actor-Critic for Discrete Action Settings](http://arxiv.org/abs/1910.07207)

* DSAC

  [DSAC: Distributional Soft Actor Critic for Risk-Sensitive Reinforcement Learning](http://arxiv.org/abs/2004.14547)

